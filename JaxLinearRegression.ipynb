{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install jax jaxlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27daIDMvuhWs",
        "outputId": "2de35788-af71-4b3c-9492-0da2b0db8366"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from jax import grad, jit\n",
        "from jax import random"
      ],
      "metadata": {
        "id": "AR2X1AOBuhzj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "key = random.PRNGKey(0)\n",
        "X = random.normal(key, (100, 1))\n",
        "true_w = 2.0\n",
        "true_b = 1.0\n",
        "y = true_w * X + true_b + random.normal(key, (100, 1)) * 0.1\n",
        "\n",
        "# Initializations\n",
        "w = random.normal(key, (1,))\n",
        "b = random.normal(key, ())"
      ],
      "metadata": {
        "id": "Al2I7IsXuUN6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear model\n",
        "def predict(X, w, b):\n",
        "    return jnp.dot(X, w) + b\n",
        "\n",
        "# Mean squared error loss\n",
        "def loss_fn(w, b, X, y):\n",
        "    preds = predict(X, w, b)\n",
        "    return jnp.mean((preds - y) ** 2)"
      ],
      "metadata": {
        "id": "Qp5DjA5iusvJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradients\n",
        "grad_fn = grad(loss_fn, argnums=(0, 1))\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.1\n",
        "for i in range(1000):\n",
        "    grads = grad_fn(w, b, X, y)\n",
        "    w -= learning_rate * grads[0]\n",
        "    b -= learning_rate * grads[1]\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        current_loss = loss_fn(w, b, X, y)\n",
        "        print(f\"Iteration {i}: loss {current_loss}\")\n",
        "\n",
        "print(f\"Trained parameters: w = {w}, b = {b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSchdXnDyVjm",
        "outputId": "b454b971-c461-4697-e78a-a63b69f6817b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: loss 5.156553745269775\n",
            "Iteration 100: loss 3.9025702476501465\n",
            "Iteration 200: loss 3.9025702476501465\n",
            "Iteration 300: loss 3.9025702476501465\n",
            "Iteration 400: loss 3.9025702476501465\n",
            "Iteration 500: loss 3.9025702476501465\n",
            "Iteration 600: loss 3.9025702476501465\n",
            "Iteration 700: loss 3.9025702476501465\n",
            "Iteration 800: loss 3.9025702476501465\n",
            "Iteration 900: loss 3.9025702476501465\n",
            "Trained parameters: w = [3.394465e-08], b = 1.172472596168518\n"
          ]
        }
      ]
    }
  ]
}