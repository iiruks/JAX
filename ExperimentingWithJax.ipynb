{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as random\n",
        "from jax import grad, jit, vmap, pmap, device_put, device_get, hessian, jacfwd, jacrev\n",
        "import jax.tree_util as tree_util\n",
        "import jax.lax as lax\n",
        "import jax.nn as nn\n",
        "#from jax.experimental import loops\n",
        "import jax.profiler as profiler\n",
        "\n",
        "# Set up JAX to use 64-bit precision\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "\n",
        "# Random number generation\n",
        "key = random.PRNGKey(0)\n",
        "x = random.normal(key, (10,))\n",
        "print(\"Random numbers:\", x)\n",
        "\n",
        "# Basic operations with grad\n",
        "def simple_func(x):\n",
        "    return jnp.sin(x) * jnp.cos(x)\n",
        "\n",
        "grad_simple_func = grad(simple_func)\n",
        "print(\"Gradient of simple_func at x=1.0:\", grad_simple_func(1.0))\n",
        "\n",
        "# Just-in-time compilation with jit\n",
        "@jit\n",
        "def compute_square(x):\n",
        "    return x ** 2\n",
        "\n",
        "print(\"Square of 3:\", compute_square(3))\n",
        "\n",
        "# Vectorized mapping with vmap\n",
        "@vmap\n",
        "def vectorized_square(x):\n",
        "    return x ** 2\n",
        "\n",
        "print(\"Vectorized squares:\", vectorized_square(jnp.arange(5)))\n",
        "\n",
        "# # Parallelized mapping with pmap\n",
        "# @pmap\n",
        "# def parallelized_square(x):\n",
        "#     return x ** 2\n",
        "\n",
        "# print(\"Parallelized squares:\", parallelized_square(jnp.arange(5)))\n",
        "\n",
        "# Using lax for control flow\n",
        "def while_loop_example(x):\n",
        "    def cond_fun(val):\n",
        "        return val < 10\n",
        "\n",
        "    def body_fun(val):\n",
        "        return val + 1\n",
        "\n",
        "    return lax.while_loop(cond_fun, body_fun, x)\n",
        "\n",
        "print(\"Result of while loop starting at 0:\", while_loop_example(0))\n",
        "\n",
        "# Device transfer\n",
        "x_device = device_put(x)\n",
        "print(\"Data on device:\", x_device)\n",
        "x_host = device_get(x_device)\n",
        "print(\"Data back on host:\", x_host)\n",
        "\n",
        "# Tree operations\n",
        "tree = {'a': x, 'b': (2, 3)}\n",
        "flat_tree, tree_def = tree_util.tree_flatten(tree)\n",
        "print(\"Flattened tree:\", flat_tree)\n",
        "restored_tree = tree_util.tree_unflatten(tree_def, flat_tree)\n",
        "print(\"Restored tree:\", restored_tree)\n",
        "\n",
        "# Lax scan\n",
        "def scan_func(carry, x):\n",
        "    return carry + x, carry + x\n",
        "\n",
        "carry, result = lax.scan(scan_func, 0, jnp.arange(5))\n",
        "print(\"Result of lax.scan:\", result)\n",
        "\n",
        "# Neural network module\n",
        "x = jnp.linspace(-5, 5, 100)\n",
        "logits = nn.relu(x)\n",
        "print(\"ReLU activation:\", logits)\n",
        "\n",
        "# Profiling\n",
        "profiler.start_trace(\"profiler_output\")\n",
        "y = compute_square(x)\n",
        "profiler.stop_trace()\n",
        "\n",
        "# Custom gradient\n",
        "@custom_grad\n",
        "def custom_func(x):\n",
        "    value = x ** 2\n",
        "    def grad_func(grad):\n",
        "        return grad * 2 * x\n",
        "    return value, grad_func\n",
        "\n",
        "print(\"Custom gradient at x=3:\", grad(custom_func)(3.0))\n",
        "\n",
        "# Hessian\n",
        "def quadratic_func(x):\n",
        "    return x ** 2\n",
        "\n",
        "hess_func = hessian(quadratic_func)\n",
        "print(\"Hessian of quadratic_func at x=1.0:\", hess_func(1.0))\n",
        "\n",
        "# Jacobian forward mode\n",
        "def func(x):\n",
        "    return jnp.array([x ** 2, x ** 3])\n",
        "\n",
        "jacobian_fwd = jacfwd(func)\n",
        "print(\"Jacobian forward mode at x=2.0:\", jacobian_fwd(2.0))\n",
        "\n",
        "# Jacobian reverse mode\n",
        "jacobian_rev = jacrev(func)\n",
        "print(\"Jacobian reverse mode at x=2.0:\", jacobian_rev(2.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "FcbD3U2ees8m",
        "outputId": "82f917c2-6195-4dde-f693-89a9134febb5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random numbers: [ 1.05451609 -0.96928879 -0.59460177 -0.03188579  2.41093278 -1.87844856\n",
            " -0.78476944 -0.31370829  0.33370904  1.76770368]\n",
            "Gradient of simple_func at x=1.0: -0.4161468365471423\n",
            "Square of 3: 9\n",
            "Vectorized squares: [ 0  1  4  9 16]\n",
            "Result of while loop starting at 0: 10\n",
            "Data on device: [ 1.05451609 -0.96928879 -0.59460177 -0.03188579  2.41093278 -1.87844856\n",
            " -0.78476944 -0.31370829  0.33370904  1.76770368]\n",
            "Data back on host: [ 1.05451609 -0.96928879 -0.59460177 -0.03188579  2.41093278 -1.87844856\n",
            " -0.78476944 -0.31370829  0.33370904  1.76770368]\n",
            "Flattened tree: [Array([ 1.05451609, -0.96928879, -0.59460177, -0.03188579,  2.41093278,\n",
            "       -1.87844856, -0.78476944, -0.31370829,  0.33370904,  1.76770368],      dtype=float64), 2, 3]\n",
            "Restored tree: {'a': Array([ 1.05451609, -0.96928879, -0.59460177, -0.03188579,  2.41093278,\n",
            "       -1.87844856, -0.78476944, -0.31370829,  0.33370904,  1.76770368],      dtype=float64), 'b': (2, 3)}\n",
            "Result of lax.scan: [ 0  1  3  6 10]\n",
            "ReLU activation: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.05050505 0.15151515 0.25252525 0.35353535\n",
            " 0.45454545 0.55555556 0.65656566 0.75757576 0.85858586 0.95959596\n",
            " 1.06060606 1.16161616 1.26262626 1.36363636 1.46464646 1.56565657\n",
            " 1.66666667 1.76767677 1.86868687 1.96969697 2.07070707 2.17171717\n",
            " 2.27272727 2.37373737 2.47474747 2.57575758 2.67676768 2.77777778\n",
            " 2.87878788 2.97979798 3.08080808 3.18181818 3.28282828 3.38383838\n",
            " 3.48484848 3.58585859 3.68686869 3.78787879 3.88888889 3.98989899\n",
            " 4.09090909 4.19191919 4.29292929 4.39393939 4.49494949 4.5959596\n",
            " 4.6969697  4.7979798  4.8989899  5.        ]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'custom_grad' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-aafe245dea55>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# Custom gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mcustom_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcustom_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'custom_grad' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bxj1Zbq0exRC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}